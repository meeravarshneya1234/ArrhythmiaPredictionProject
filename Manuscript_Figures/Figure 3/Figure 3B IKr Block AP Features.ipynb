{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Data \n",
    "filename = 'C:/TestPopulation/Data/Population_Feature_Outputs.csv' # file with data \n",
    "label = 'IKrBlock_Label'\n",
    "features = ['Vrest', 'Upstroke', 'Vpeak', 'APD20', 'APD40', 'APD50', 'APD90',\n",
    "       'TriAP']\n",
    "\n",
    "# Output Data \n",
    "folder_save = 'C:/TestPopulation/Data/'\n",
    "output_name = 'SteadyState_APFeatures_IKrBlock'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, normalize\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings \n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import machine_learning_funs as ml\n",
    "import tune_parameters as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot settings \n",
    "sns.set_style(\"dark\")\n",
    "sns.despine()\n",
    "sns.set_context(\"notebook\", font_scale=2, rc={\"lines.linewidth\": 5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed\n",
    "seed = 134556\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df = pd.read_csv(filename)\n",
    "df = df.dropna()\n",
    "y = df[[label]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[features]\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the inputs\n",
    "x = df1 \n",
    "x_1 = StandardScaler().fit_transform(x) # for other classifiers except ANN\n",
    "x_2 = MinMaxScaler().fit_transform(x) # for ANN only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train, test set\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_1, y, random_state = seed, test_size = 0.10)\n",
    "x_train_ann, x_test_ann, y_train_ann, y_test_ann = train_test_split(x_2, y, random_state = seed, test_size = 0.10)\n",
    "\n",
    "print('Train Set Size = ' + str(x_train.shape[0]))\n",
    "print('Test Set Size = ' + str(x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfold = 3\n",
    "lr_GKr = pt.lr_param_selection(x_train, y_train, nfolds = nfold, seed = seed)\n",
    "svc_GKr = pt.svc_param_selection(x_train, y_train, nfolds = nfold, seed = seed)\n",
    "knn_GKr = pt.knn_param_selection(x_train, y_train, nfolds = nfold, seed = seed)\n",
    "rfc_GKr = pt.random_forest_selection(x_train, y_train, nfolds=nfold, seed = seed)\n",
    "gb_GKr = pt.gradientboosting_selection(x_train, y_train, nfolds=nfold, seed = seed)\n",
    "xgb_GKr = pt.xgboost_selection(x_train, y_train, nfolds=nfold, seed = seed)\n",
    "ann_GKr = pt.ann_selection(x_train_ann, y_train_ann, nfolds=nfold, seed = seed)\n",
    "gnb_GKr = pt.nb_selection(x_train, y_train, nfolds=nfold, seed = seed)\n",
    "\n",
    "keys = ['RF', 'KNN', 'LR', 'GB', 'SVM','ANN','Bayes','XGB']\n",
    "classifiers_GKr = [rfc_GKr, knn_GKr, lr_GKr, gb_GKr,svc_GKr, ann_GKr, gnb_GKr, xgb_GKr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_GKr = ml.create_table(x_train_ann,x_test_ann,y_train_ann,y_test_ann,x_train,x_test,y_train,y_test,classifiers_GKr,keys)\n",
    "result_table = output_GKr[0]\n",
    "metrics = output_GKr[1]\n",
    "rocs = output_GKr[2]\n",
    "prob = output_GKr[3]\n",
    "pred = output_GKr[4]\n",
    "conf_matrix = output_GKr[5]\n",
    "\n",
    "output_GKr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml.plot_algs(rocs,result_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob = ml.save_prob(prob,y_test,keys)\n",
    "df_pred = ml.save_pred(pred,y_test,keys)\n",
    "df_roc = ml.save_ROCs(rocs,keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "save_filename = folder_save + output_name + '.xlsx'\n",
    "exists = os.path.isfile(save_filename)\n",
    "if exists:\n",
    "    print(\"File already exists\")\n",
    "else:\n",
    "    writer = pd.ExcelWriter(save_filename, engine='xlsxwriter')\n",
    "    result_table.to_excel(writer, sheet_name = 'Results')\n",
    "    df_roc.to_excel(writer, sheet_name='ROCs',index=False)\n",
    "    df_pred.to_excel(writer, sheet_name='Prediction')\n",
    "    df_prob.to_excel(writer, sheet_name='Probability')\n",
    "    writer.save()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2\n",
    "#import rpy2.robjects.packages as rpackages\n",
    "#from rpy2.robjects.vectors import StrVector\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects import pandas2ri\n",
    "pandas2ri.activate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'print.me': 'print_dot_me', 'print_me': 'print_uscore_me'}\n",
    "try:\n",
    "    proc = importr('pROC', robject_translations = d, lib_loc = \"C:/Users/MeeraVarshneya/Documents/R/win-library/3.6\")\n",
    "except:\n",
    "    proc = importr('pROC', robject_translations = d, lib_loc = \"C:/Program Files/R/R-3.6.1/library\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = df_prob.Label\n",
    "rf = df_prob.RF\n",
    "knn = df_prob.KNN\n",
    "lr = df_prob.LR\n",
    "gb = df_prob.GB\n",
    "svm = df_prob.SVM\n",
    "ann = df_prob.ANN\n",
    "bayes = df_prob.Bayes\n",
    "xgb = df_prob.XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_rf = proc.roc(l, rf)\n",
    "roc_knn = proc.roc(l, knn)\n",
    "roc_lr = proc.roc(l, lr)\n",
    "roc_gb = proc.roc(l, gb)\n",
    "roc_svm = proc.roc(l, svm)\n",
    "roc_ann = proc.roc(l, ann)\n",
    "roc_bayes = proc.roc(l, bayes)\n",
    "roc_xgb = proc.roc(l, xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAUC = result_table.AUC \n",
    "max_AUC = dfAUC.idxmax(axis=0, skipna=True)\n",
    "max_AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ci(roc_object):\n",
    "    x = proc.ci_auc(roc_object)\n",
    "    lower = x[0]\n",
    "    upper = x[-1]\n",
    "    return ['{:.2f}'.format(lower), '{:.2f}'.format(upper)]\n",
    "\n",
    "def get_pvalue(roc1, roc2):\n",
    "    y = proc.roc_test(roc1, roc2, alternative = 'two.sided')\n",
    "    p = np.array(y.rx2('p.value'))\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = get_pvalue(roc_svm, roc_rf)\n",
    "print('SVM vs RF:', p)\n",
    "p = get_pvalue(roc_svm, roc_knn)\n",
    "print('SVM vs KNN:', p)\n",
    "p = get_pvalue(roc_svm, roc_lr)\n",
    "print('SVM vs LR:', p)\n",
    "p = get_pvalue(roc_svm, roc_gb)\n",
    "print('SVM vs GB:', p)\n",
    "p = get_pvalue(roc_svm, roc_ann)\n",
    "print('SVM vs ANN:', p)\n",
    "p = get_pvalue(roc_svm, roc_bayes)\n",
    "print('SVM vs Bayes:', p)\n",
    "p = get_pvalue(roc_svm, roc_xgb)\n",
    "print('SVM vs XGB:', p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar\n",
    "def get_p(df, model1, model2):\n",
    "    table = pd.crosstab(df[model1], df[model2])\n",
    "    result = mcnemar(table, exact=True)\n",
    "    print('p-value=%.5f'%result.pvalue)\n",
    "    return result.pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoffs = result_table.Threshold\n",
    "dfprob = pd.DataFrame()\n",
    "for idx, clf in enumerate(prob[:8]):\n",
    "    dfprob[keys[idx]] = clf[:, 1]\n",
    "    dfprob[keys[idx]+\"_pred\"] = clf[:, 1]>cutoffs[idx]\n",
    "dfprob['Label'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfprob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsen = dfprob[dfprob['Label']==1] ## True positives\n",
    "dfspe = dfprob[dfprob['Label']==0] ## True negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_p(dfsen, 'SVM_pred', 'RF_pred') # sensitivity shows significant difference \n",
    "get_p(dfsen, 'SVM_pred', 'LR_pred') # sensitivity shows significant difference \n",
    "get_p(dfsen, 'SVM_pred', 'ANN_pred') # sensitivity shows significant difference \n",
    "get_p(dfsen, 'SVM_pred', 'XGB_pred') # sensitivity shows significant difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_p(dfspe, 'SVM_pred', 'RF_pred')# specificity shows significant difference \n",
    "get_p(dfspe, 'SVM_pred', 'LR_pred') # sensitivity shows significant difference \n",
    "get_p(dfspe, 'SVM_pred', 'ANN_pred') # sensitivity shows significant difference \n",
    "get_p(dfspe, 'SVM_pred', 'XGB_pred') # sensitivity shows significant difference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
